diff --git a/api/Dockerfile b/api/Dockerfile
index 7e4997507f..c92526d0fc 100644
--- a/api/Dockerfile
+++ b/api/Dockerfile
@@ -31,6 +31,7 @@ ENV CONSOLE_API_URL=http://127.0.0.1:5001
 ENV CONSOLE_WEB_URL=http://127.0.0.1:3000
 ENV SERVICE_API_URL=http://127.0.0.1:5001
 ENV APP_WEB_URL=http://127.0.0.1:3000
+ENV SECRET_KEY=Cj7R6c4W/mjGqZGfLA9ZcR6oP01KOAz/qtVTAPi8Vao5Hg6nx5BKra5z
 
 EXPOSE 5001
 
diff --git a/api/controllers/console/app/app.py b/api/controllers/console/app/app.py
index 860166a61a..f230a013ed 100644
--- a/api/controllers/console/app/app.py
+++ b/api/controllers/console/app/app.py
@@ -24,10 +24,37 @@ from services.app_dsl_service import AppDslService, ImportMode
 from services.app_service import AppService
 from services.enterprise.enterprise_service import EnterpriseService
 from services.feature_service import FeatureService
+from services.tag_service import TagService
 
 ALLOW_CREATE_APP_MODES = ["chat", "agent-chat", "advanced-chat", "workflow", "completion"]
 
 
+class AppExportFirestoreApi(Resource):
+    @setup_required
+    @login_required
+    @account_initialization_required
+    @get_app_model
+    @marshal_with(app_detail_fields_with_site)
+    def post(self, app_model):
+        """Export App Firestore"""
+        # The role of the current user in the ta table must be admin, owner, or editor
+        if not current_user.is_editor:
+            raise Forbidden()
+        parser = reqparse.RequestParser()
+        parser.add_argument("appID", type=str, location="json")
+        parser.add_argument("paramID", type=str, location="json")
+        parser.add_argument("name", type=str, location="json")
+        parser.add_argument("description", type=str, location="json")
+        parser.add_argument("icon", type=str, location="json")
+        parser.add_argument("icon_background", type=str, location="json")
+        parser.add_argument("category", type=str, choices=ALLOW_CREATE_APP_MODES, location="json")
+        parser.add_argument("has_knowledge_base", type=bool, location="json")
+        args = parser.parse_args()
+        app_service = AppService()
+        app_service.export_to_firestore(args)
+        return 201
+
+
 class AppListApi(Resource):
     @setup_required
     @login_required
@@ -63,12 +90,39 @@ class AppListApi(Resource):
         )
         parser.add_argument("name", type=str, location="args", required=False)
         parser.add_argument("tag_ids", type=uuid_list, location="args", required=False)
+        parser.add_argument("tag_names", type=str, location="args", required=False)
         parser.add_argument("is_created_by_me", type=inputs.boolean, location="args", required=False)
 
         args = parser.parse_args()
 
         # get app list
         app_service = AppService()
+        
+        # Filter by tag names if provided
+        if args.get("tag_names"):
+            tag_names = [name.strip() for name in args["tag_names"].split(",")]
+            tag_ids = []
+            
+            # Get tag IDs for the given tag names
+            for tag_name in tag_names:
+                tags = TagService.get_tag_by_tag_name("app", current_user.current_tenant_id, tag_name)
+                if tags:
+                    tag_ids.extend([tag.id for tag in tags])
+            
+            # If tag IDs were found, add them to args
+            if tag_ids:
+                if args.get("tag_ids"):
+                    # Combine with existing tag_ids if any
+                    existing_ids = args["tag_ids"]
+                    # Deduplicate while preserving order
+                    combined_ids = existing_ids + tag_ids
+                    args["tag_ids"] = list(dict.fromkeys(combined_ids))
+                else:
+                    args["tag_ids"] = tag_ids
+            elif args.get("tag_names") and not args.get("tag_ids"):
+                # If tag names were provided but no matching tags found, return empty result
+                return {"data": [], "total": 0, "page": 1, "limit": 20, "has_more": False}
+        
         app_pagination = app_service.get_paginate_apps(current_user.id, current_user.current_tenant_id, args)
         if not app_pagination:
             return {"data": [], "total": 0, "page": 1, "limit": 20, "has_more": False}
@@ -114,6 +168,62 @@ class AppListApi(Resource):
         return app, 201
 
 
+# class AppImportApi(Resource):
+#     @setup_required
+#     @login_required
+#     @account_initialization_required
+#     @marshal_with(app_detail_fields_with_site)
+#     @cloud_edition_billing_resource_check("apps")
+#     def post(self):
+#         """Import app"""
+#         # The role of the current user in the ta table must be admin, owner, or editor
+#         if not current_user.is_editor:
+#             raise Forbidden()
+
+#         parser = reqparse.RequestParser()
+#         parser.add_argument("data", type=str, required=True, nullable=False, location="json")
+#         parser.add_argument("name", type=str, location="json")
+#         parser.add_argument("description", type=str, location="json")
+#         parser.add_argument("icon_type", type=str, location="json")
+#         parser.add_argument("icon", type=str, location="json")
+#         parser.add_argument("icon_background", type=str, location="json")
+#         parser.add_argument("asa_company_id", type=str, location="json")
+#         args = parser.parse_args()
+
+#         app = AppDslService.import_and_create_new_app(
+#             tenant_id=current_user.current_tenant_id, data=args["data"], args=args, account=current_user
+#         )
+
+#         return app, 201
+
+
+# class AppImportFromUrlApi(Resource):
+#     @setup_required
+#     @login_required
+#     @account_initialization_required
+#     @marshal_with(app_detail_fields_with_site)
+#     @cloud_edition_billing_resource_check("apps")
+#     def post(self):
+#         """Import app from url"""
+#         # The role of the current user in the ta table must be admin, owner, or editor
+#         if not current_user.is_editor:
+#             raise Forbidden()
+
+#         parser = reqparse.RequestParser()
+#         parser.add_argument("url", type=str, required=True, nullable=False, location="json")
+#         parser.add_argument("name", type=str, location="json")
+#         parser.add_argument("description", type=str, location="json")
+#         parser.add_argument("icon", type=str, location="json")
+#         parser.add_argument("icon_background", type=str, location="json")
+#         args = parser.parse_args()
+
+#         app = AppDslService.import_and_create_new_app_from_url(
+#             tenant_id=current_user.current_tenant_id, url=args["url"], args=args, account=current_user
+#         )
+
+#         return app, 201
+
+
 class AppApi(Resource):
     @setup_required
     @login_required
@@ -354,6 +464,7 @@ class AppTraceApi(Resource):
 api.add_resource(AppListApi, "/apps")
 api.add_resource(AppApi, "/apps/<uuid:app_id>")
 api.add_resource(AppCopyApi, "/apps/<uuid:app_id>/copy")
+api.add_resource(AppExportFirestoreApi, "/apps/<uuid:app_id>/exportFirestore")
 api.add_resource(AppExportApi, "/apps/<uuid:app_id>/export")
 api.add_resource(AppNameApi, "/apps/<uuid:app_id>/name")
 api.add_resource(AppIconApi, "/apps/<uuid:app_id>/icon")
diff --git a/api/controllers/console/app/app_import.py b/api/controllers/console/app/app_import.py
index 9ffb94e9f9..0a1559dc7f 100644
--- a/api/controllers/console/app/app_import.py
+++ b/api/controllers/console/app/app_import.py
@@ -42,6 +42,7 @@ class AppImportApi(Resource):
         parser.add_argument("icon", type=str, location="json")
         parser.add_argument("icon_background", type=str, location="json")
         parser.add_argument("app_id", type=str, location="json")
+        parser.add_argument("asa_company_id", type=str, location="json")
         args = parser.parse_args()
 
         # Create service with session
@@ -60,6 +61,7 @@ class AppImportApi(Resource):
                 icon=args.get("icon"),
                 icon_background=args.get("icon_background"),
                 app_id=args.get("app_id"),
+                asa_company_id=args.get("asa_company_id"),
             )
             session.commit()
         if result.app_id and FeatureService.get_system_features().webapp_auth.enabled:
diff --git a/api/controllers/console/app/conversation.py b/api/controllers/console/app/conversation.py
index 70d6216497..0b2548e138 100644
--- a/api/controllers/console/app/conversation.py
+++ b/api/controllers/console/app/conversation.py
@@ -1,3 +1,4 @@
+import decimal
 from datetime import UTC, datetime
 
 import pytz  # pip install pytz
@@ -17,6 +18,7 @@ from fields.conversation_fields import (
     conversation_detail_fields,
     conversation_message_detail_fields,
     conversation_pagination_fields,
+    conversation_statistics_fields,
     conversation_with_summary_pagination_fields,
 )
 from libs.helper import DatetimeString
@@ -24,7 +26,6 @@ from libs.login import login_required
 from models import Conversation, EndUser, Message, MessageAnnotation
 from models.model import AppMode
 
-
 class CompletionConversationApi(Resource):
     @setup_required
     @login_required
@@ -298,10 +299,51 @@ class ChatConversationDetailApi(Resource):
         return {"result": "success"}, 204
 
 
+# Custom ASA endpoint
+class ConversationStatisticsApi(Resource):
+    @setup_required
+    @login_required
+    @account_initialization_required
+    @get_app_model(mode=[AppMode.CHAT, AppMode.AGENT_CHAT, AppMode.ADVANCED_CHAT, AppMode.COMPLETION])
+    @marshal_with(conversation_statistics_fields)
+    def get(self, app_model, conversation_id):
+        if not current_user.is_editor:
+            raise Forbidden()
+        conversation_id = str(conversation_id)
+
+        conversation = _get_conversation(app_model, conversation_id)
+
+        # Fetch all messages for the conversation
+        messages = db.session.query(Message).filter(Message.conversation_id == conversation.id).all()
+
+        total_messages = len(messages)
+        total_tokens = 0
+        total_price = decimal.Decimal(0.0)
+        currency = "USD"  # Default currency
+
+        for message in messages:
+            total_tokens += message.message_tokens + message.answer_tokens
+            if message.total_price:
+                total_price += message.total_price
+            if message.currency:
+                currency = message.currency
+
+        return {
+            "total_messages": total_messages,
+            "total_tokens": total_tokens,
+            "total_price": total_price,
+            "currency": currency,
+        }
+
+
 api.add_resource(CompletionConversationApi, "/apps/<uuid:app_id>/completion-conversations")
 api.add_resource(CompletionConversationDetailApi, "/apps/<uuid:app_id>/completion-conversations/<uuid:conversation_id>")
 api.add_resource(ChatConversationApi, "/apps/<uuid:app_id>/chat-conversations")
 api.add_resource(ChatConversationDetailApi, "/apps/<uuid:app_id>/chat-conversations/<uuid:conversation_id>")
+api.add_resource(
+    ConversationStatisticsApi, "/apps/<uuid:app_id>/conversations/<uuid:conversation_id>/statistics"
+)
+
 
 
 def _get_conversation(app_model, conversation_id):
diff --git a/api/controllers/console/app/workflow_run.py b/api/controllers/console/app/workflow_run.py
index 9099700213..cf8eba546d 100644
--- a/api/controllers/console/app/workflow_run.py
+++ b/api/controllers/console/app/workflow_run.py
@@ -1,3 +1,4 @@
+import decimal
 from typing import cast
 
 from flask_login import current_user
@@ -12,6 +13,7 @@ from fields.workflow_run_fields import (
     workflow_run_detail_fields,
     workflow_run_node_execution_list_fields,
     workflow_run_pagination_fields,
+    workflow_run_statistics_fields,
 )
 from libs.helper import uuid_value
 from libs.login import login_required
@@ -19,6 +21,7 @@ from models import Account, App, AppMode, EndUser
 from services.workflow_run_service import WorkflowRunService
 
 
+
 class AdvancedChatAppWorkflowRunListApi(Resource):
     @setup_required
     @login_required
@@ -101,8 +104,49 @@ class WorkflowRunNodeExecutionListApi(Resource):
 
         return {"data": node_executions}
 
+# Custom ASA endpoint
+class WorkflowRunStatisticsApi(Resource):
+    @setup_required
+    @login_required
+    @account_initialization_required
+    @get_app_model(mode=[AppMode.ADVANCED_CHAT, AppMode.WORKFLOW])
+    @marshal_with(workflow_run_statistics_fields)
+    def get(self, app_model: App, run_id):
+        """
+        Get workflow run statistics
+        """
+        run_id = str(run_id)
+
+        workflow_run_service = WorkflowRunService()
+        user = cast("Account | EndUser", current_user)
+        node_executions = workflow_run_service.get_workflow_run_node_executions(
+            app_model=app_model,
+            run_id=run_id,
+            user=user,
+        )
+
+        total_tokens = 0
+        total_price = decimal.Decimal(0.0)
+        currency = "USD"
+
+        for node_execution in node_executions:
+            metadata = node_execution.execution_metadata_dict
+            if metadata and "total_tokens" in metadata:
+                total_tokens += metadata["total_tokens"]
+            if metadata and "total_price" in metadata:
+                total_price += decimal.Decimal(str(metadata["total_price"]))
+            if metadata and "currency" in metadata:
+                currency = metadata["currency"]
+
+        return {
+            "total_tokens": total_tokens,
+            "total_price": float(total_price),
+            "currency": currency,
+        }
+
 
 api.add_resource(AdvancedChatAppWorkflowRunListApi, "/apps/<uuid:app_id>/advanced-chat/workflow-runs")
 api.add_resource(WorkflowRunListApi, "/apps/<uuid:app_id>/workflow-runs")
 api.add_resource(WorkflowRunDetailApi, "/apps/<uuid:app_id>/workflow-runs/<uuid:run_id>")
 api.add_resource(WorkflowRunNodeExecutionListApi, "/apps/<uuid:app_id>/workflow-runs/<uuid:run_id>/node-executions")
+api.add_resource(WorkflowRunStatisticsApi, "/apps/<uuid:app_id>/workflow-runs/<uuid:run_id>/statistics")
diff --git a/api/controllers/console/auth/login.py b/api/controllers/console/auth/login.py
index 5f2a24322d..a877ba0973 100644
--- a/api/controllers/console/auth/login.py
+++ b/api/controllers/console/auth/login.py
@@ -26,6 +26,7 @@ from controllers.console.error import (
 from controllers.console.wraps import email_password_login_enabled, setup_required
 from events.tenant_event import tenant_was_created
 from libs.helper import email, extract_remote_ip
+from libs.passport import PassportService
 from libs.password import valid_password
 from models.account import Account
 from services.account_service import AccountService, RegisterService, TenantService
@@ -34,6 +35,8 @@ from services.errors.account import AccountRegisterError
 from services.errors.workspace import WorkSpaceNotAllowedCreateError, WorkspacesLimitExceededError
 from services.feature_service import FeatureService
 
+ASA_ACCOUNT_EMAIL = 'webmasters@asa.team'
+
 
 class LoginApi(Resource):
     """Resource for user login."""
@@ -102,6 +105,39 @@ class LoginApi(Resource):
         token_pair = AccountService.login(account=account, ip_address=extract_remote_ip(request))
         AccountService.reset_login_error_rate_limit(args["email"])
         return {"result": "success", "data": token_pair.model_dump()}
+    
+
+class SharedAccountLoginApi(Resource):
+    """Resource for shared account login with external user tracking."""
+
+    @staticmethod
+    def post():
+        token = request.headers.get("Authorization")
+        print('token', token)
+        if not token:
+            return {"result": "fail", "data": "Authorization token is missing"}, 401
+        
+        payload = PassportService().verify(token)
+        user_email = payload.get("email")
+        asa_uid = payload.get("asa_uid")
+        print('decoded token', payload)
+        if not user_email or not asa_uid:
+            return {"result": "fail", "data": "Email or external user ID not provided in token"}, 400
+
+        # Ensure only one main account is used
+        account = AccountService.get_user_through_email(ASA_ACCOUNT_EMAIL)
+        if not account:
+            account = AccountService.create_account(
+                email=ASA_ACCOUNT_EMAIL,
+                name=user_email,
+                interface_language="en-US"
+            )
+
+        # Include `asa_uid` in the login metadata for tracking
+        token_pair = AccountService.login(account=account)
+        print('token_pair', token_pair)
+        AccountService.reset_login_error_rate_limit(user_email)
+        return {"result": "success", "data": token_pair.model_dump()}
 
 
 class LogoutApi(Resource):
@@ -245,6 +281,7 @@ class RefreshTokenApi(Resource):
 
 
 api.add_resource(LoginApi, "/login")
+api.add_resource(SharedAccountLoginApi, "/external-login")
 api.add_resource(LogoutApi, "/logout")
 api.add_resource(EmailCodeLoginSendEmailApi, "/email-code-login")
 api.add_resource(EmailCodeLoginApi, "/email-code-login/validity")
diff --git a/api/controllers/console/datasets/datasets.py b/api/controllers/console/datasets/datasets.py
index 1611214cb3..4d53daf641 100644
--- a/api/controllers/console/datasets/datasets.py
+++ b/api/controllers/console/datasets/datasets.py
@@ -31,6 +31,7 @@ from fields.document_fields import document_status_fields
 from libs.login import login_required
 from models import ApiToken, Dataset, Document, DocumentSegment, UploadFile
 from models.dataset import DatasetPermissionEnum
+from services.app_dsl_service import AppDslService
 from services.dataset_service import DatasetPermissionService, DatasetService, DocumentService
 
 
@@ -146,6 +147,24 @@ class DatasetListApi(Resource):
             nullable=True,
             required=False,
         )
+        parser.add_argument(
+            "asa_company_id",
+            type=str,
+            nullable=True,
+            required=False,
+        )
+        parser.add_argument(
+            "asa_uid",
+            type=str,
+            nullable=True,
+            required=False,
+        )
+        parser.add_argument(
+            "access_scope",
+            type=str,
+            nullable=True,
+            required=False,
+        )
         args = parser.parse_args()
 
         # The role of the current user in the ta table must be admin, owner, or editor, or dataset_operator
@@ -163,6 +182,9 @@ class DatasetListApi(Resource):
                 provider=args["provider"],
                 external_knowledge_api_id=args["external_knowledge_api_id"],
                 external_knowledge_id=args["external_knowledge_id"],
+                asa_company_id=args["asa_company_id"],
+                asa_uid=args["asa_uid"],
+                access_scope=args["access_scope"]
             )
         except services.errors.dataset.DatasetNameDuplicateError:
             raise DatasetNameDuplicateError()
@@ -793,6 +815,44 @@ class DatasetAutoDisableLogApi(Resource):
             raise NotFound("Dataset not found.")
         return DatasetService.get_dataset_auto_disable_logs(dataset_id_str), 200
 
+class DatasetEncryptionApi(Resource):
+    @setup_required
+    @login_required
+    @account_initialization_required
+    def post(self):
+        """
+        Encrypt a dataset ID (Custom asa endpoint)
+        """
+        # The role of the current user in the ta table must be admin, owner, or editor
+        if not current_user.is_editor:
+            raise Forbidden()
+            
+        parser = reqparse.RequestParser()
+        parser.add_argument('dataset_id', type=str, required=True, location='json')
+        args = parser.parse_args()
+        
+        dataset_id = args['dataset_id']
+        
+        # Validate that the dataset exists and the user has access to it
+        dataset = DatasetService.get_dataset(dataset_id)
+        if dataset is None:
+            raise NotFound("Dataset not found.")
+        
+        try:
+            DatasetService.check_dataset_permission(dataset, current_user)
+        except services.errors.account.NoPermissionError as e:
+            raise Forbidden(str(e))
+        
+        # Encrypt the dataset ID
+        encrypted_id = AppDslService.encrypt_dataset_id(
+            dataset_id=dataset_id,
+            tenant_id=current_user.current_tenant_id
+        )
+        
+        return {
+            'encrypted_id': encrypted_id
+        }, 200
+
 
 api.add_resource(DatasetListApi, "/datasets")
 api.add_resource(DatasetApi, "/datasets/<uuid:dataset_id>")
@@ -809,3 +869,4 @@ api.add_resource(DatasetRetrievalSettingApi, "/datasets/retrieval-setting")
 api.add_resource(DatasetRetrievalSettingMockApi, "/datasets/retrieval-setting/<string:vector_type>")
 api.add_resource(DatasetPermissionUserListApi, "/datasets/<uuid:dataset_id>/permission-part-users")
 api.add_resource(DatasetAutoDisableLogApi, "/datasets/<uuid:dataset_id>/auto-disable-logs")
+api.add_resource(DatasetEncryptionApi, "/datasets/encrypt")
diff --git a/api/controllers/console/explore/installed_app.py b/api/controllers/console/explore/installed_app.py
index 9d0c08564e..790d27627d 100644
--- a/api/controllers/console/explore/installed_app.py
+++ b/api/controllers/console/explore/installed_app.py
@@ -19,6 +19,7 @@ from services.account_service import TenantService
 from services.app_service import AppService
 from services.enterprise.enterprise_service import EnterpriseService
 from services.feature_service import FeatureService
+from services.tag_service import TagService
 
 logger = logging.getLogger(__name__)
 
@@ -29,6 +30,7 @@ class InstalledAppsListApi(Resource):
     @marshal_with(installed_app_list_fields)
     def get(self):
         app_id = request.args.get("app_id", default=None, type=str)
+        tag_names = request.args.get("tag_names", default=None, type=str)
         current_tenant_id = current_user.current_tenant_id
 
         if app_id:
@@ -55,6 +57,31 @@ class InstalledAppsListApi(Resource):
             if installed_app.app is not None
         ]
 
+        # Filter by tag names if provided
+        if tag_names:
+            tag_name_list = [name.strip() for name in tag_names.split(",")]
+            tag_ids = []
+            
+            # Get tag IDs for the given tag names
+            for tag_name in tag_name_list:
+                tags = TagService.get_tag_by_tag_name("app", current_user.current_tenant_id, tag_name)
+                if tags:
+                    tag_ids.extend([tag.id for tag in tags])
+            
+            # Filter installed apps by tag IDs
+            if tag_ids:
+                filtered_apps = []
+                for installed_app in installed_app_list:
+                    app_tags = installed_app["app"].tags
+                    app_tag_ids = [tag.id for tag in app_tags]
+                    # If any of the app's tags match the requested tags, include it
+                    if any(tag_id in tag_ids for tag_id in app_tag_ids):
+                        filtered_apps.append(installed_app)
+                installed_app_list = filtered_apps
+            else:
+                # If tag names were provided but no matching tags found, return empty result
+                return {"installed_apps": []}
+
         # filter out apps that user doesn't have access to
         if FeatureService.get_system_features().webapp_auth.enabled:
             user_id = current_user.id
diff --git a/api/controllers/service_api/dataset/dataset.py b/api/controllers/service_api/dataset/dataset.py
index a499719fc3..d26e29c386 100644
--- a/api/controllers/service_api/dataset/dataset.py
+++ b/api/controllers/service_api/dataset/dataset.py
@@ -128,6 +128,24 @@ class DatasetListApi(DatasetApiResource):
             nullable=True,
             required=False,
         )
+        parser.add_argument(
+            "asa_company_id",
+            type=str,
+            nullable=True,
+            required=False,
+        )
+        parser.add_argument(
+            "asa_uid",
+            type=str,
+            nullable=True,
+            required=False,
+        )
+        parser.add_argument(
+            "access_scope",
+            type=str,
+            nullable=True,
+            required=False,
+        )
         parser.add_argument("retrieval_model", type=dict, required=False, nullable=True, location="json")
         parser.add_argument("embedding_model", type=str, required=False, nullable=True, location="json")
         parser.add_argument("embedding_model_provider", type=str, required=False, nullable=True, location="json")
@@ -160,6 +178,9 @@ class DatasetListApi(DatasetApiResource):
                 provider=args["provider"],
                 external_knowledge_api_id=args["external_knowledge_api_id"],
                 external_knowledge_id=args["external_knowledge_id"],
+                asa_company_id=args["asa_company_id"],
+                asa_uid=args["asa_uid"],
+                access_scope=args["access_scope"],
                 embedding_model_provider=args["embedding_model_provider"],
                 embedding_model_name=args["embedding_model"],
                 retrieval_model=RetrievalModel(**args["retrieval_model"])
diff --git a/api/core/file/upload_file_parser.py b/api/core/file/upload_file_parser.py
new file mode 100644
index 0000000000..96b2884811
--- /dev/null
+++ b/api/core/file/upload_file_parser.py
@@ -0,0 +1,67 @@
+import base64
+import logging
+import time
+from typing import Optional
+
+from configs import dify_config
+from constants import IMAGE_EXTENSIONS
+from core.helper.url_signer import UrlSigner
+from extensions.ext_storage import storage
+
+
+class UploadFileParser:
+    @classmethod
+    def get_image_data(cls, upload_file, force_url: bool = False) -> Optional[str]:
+        if not upload_file:
+            return None
+
+        if upload_file.extension not in IMAGE_EXTENSIONS:
+            return None
+
+        if dify_config.MULTIMODAL_SEND_FORMAT == "url" or force_url:
+            return cls.get_signed_temp_image_url(upload_file.id)
+        else:
+            # get image file base64
+            try:
+                data = storage.load(upload_file.key)
+            except FileNotFoundError:
+                logging.exception(f"File not found: {upload_file.key}")
+                return None
+
+            encoded_string = base64.b64encode(data).decode("utf-8")
+            return f"data:{upload_file.mime_type};base64,{encoded_string}"
+
+    @classmethod
+    def get_signed_temp_image_url(cls, upload_file_id) -> str:
+        """
+        get signed url from upload file
+
+        :param upload_file_id: the id of UploadFile object
+        :return:
+        """
+        base_url = dify_config.FILES_URL
+        image_preview_url = f"{base_url}/files/{upload_file_id}/image-preview"
+
+        return UrlSigner.get_signed_url(url=image_preview_url, sign_key=upload_file_id, prefix="image-preview")
+
+    @classmethod
+    def verify_image_file_signature(cls, upload_file_id: str, timestamp: str, nonce: str, sign: str) -> bool:
+        """
+        verify signature
+
+        :param upload_file_id: file id
+        :param timestamp: timestamp
+        :param nonce: nonce
+        :param sign: signature
+        :return:
+        """
+        result = UrlSigner.verify(
+            sign_key=upload_file_id, timestamp=timestamp, nonce=nonce, sign=sign, prefix="image-preview"
+        )
+
+        # verify signature
+        if not result:
+            return False
+
+        current_time = int(time.time())
+        return current_time - int(timestamp) <= dify_config.FILES_ACCESS_TIMEOUT
diff --git a/api/core/indexing_runner.py b/api/core/indexing_runner.py
index 305a9190d5..a64f19e9d0 100644
--- a/api/core/indexing_runner.py
+++ b/api/core/indexing_runner.py
@@ -320,7 +320,8 @@ class IndexingRunner:
                     if image_file is None:
                         continue
                     try:
-                        storage.delete(image_file.key)
+                        if image_file:
+                            storage.delete(image_file.key)
                     except Exception:
                         logging.exception(
                             "Delete image_files failed while indexing_estimate, \
diff --git a/api/core/tools/tool_manager.py b/api/core/tools/tool_manager.py
index adae56cd27..7ff1844bd8 100644
--- a/api/core/tools/tool_manager.py
+++ b/api/core/tools/tool_manager.py
@@ -354,7 +354,6 @@ class ToolManager:
         """
         get the workflow tool runtime
         """
-
         tool_runtime = cls.get_tool_runtime(
             provider_type=workflow_tool.provider_type,
             provider_id=workflow_tool.provider_id,
diff --git a/api/fields/app_fields.py b/api/fields/app_fields.py
index 73c224542a..955c086d3d 100644
--- a/api/fields/app_fields.py
+++ b/api/fields/app_fields.py
@@ -112,6 +112,7 @@ app_partial_fields = {
     "updated_by": fields.String,
     "updated_at": TimestampField,
     "tags": fields.List(fields.Nested(tag_fields)),
+    "asa_company_id": fields.String,
     "access_mode": fields.String,
     "create_user_name": fields.String,
     "author_name": fields.String,
@@ -193,6 +194,7 @@ app_detail_fields_with_site = {
     "updated_by": fields.String,
     "updated_at": TimestampField,
     "deleted_tools": fields.List(fields.Nested(deleted_tool_fields)),
+    'asa_company_id': fields.String,
     "access_mode": fields.String,
 }
 
diff --git a/api/fields/conversation_fields.py b/api/fields/conversation_fields.py
index 370e8a5a58..deeec80599 100644
--- a/api/fields/conversation_fields.py
+++ b/api/fields/conversation_fields.py
@@ -68,6 +68,8 @@ message_detail_fields = {
     "message_tokens": fields.Integer,
     "answer": fields.String(attribute="re_sign_file_url_answer"),
     "answer_tokens": fields.Integer,
+    "total_price": fields.Float,
+    "currency": fields.String,
     "provider_response_latency": fields.Float,
     "from_source": fields.String,
     "from_end_user_id": fields.String,
@@ -209,3 +211,11 @@ conversation_infinite_scroll_pagination_fields = {
     "has_more": fields.Boolean,
     "data": fields.List(fields.Nested(simple_conversation_fields)),
 }
+
+conversation_statistics_fields = {
+    "total_messages": fields.Integer,
+    "total_tokens": fields.Integer,
+    "total_price": fields.Float,
+    "currency": fields.String,
+}
+
diff --git a/api/fields/dataset_fields.py b/api/fields/dataset_fields.py
index 32a88cc5db..fa1cd9ae96 100644
--- a/api/fields/dataset_fields.py
+++ b/api/fields/dataset_fields.py
@@ -81,6 +81,9 @@ dataset_detail_fields = {
     "external_retrieval_model": fields.Nested(external_retrieval_model_fields, allow_null=True),
     "doc_metadata": fields.List(fields.Nested(doc_metadata_fields)),
     "built_in_field_enabled": fields.Boolean,
+    "asa_company_id": fields.String,
+    "asa_uid": fields.String,
+    "access_scope": fields.String,
 }
 
 dataset_query_detail_fields = {
diff --git a/api/fields/installed_app_fields.py b/api/fields/installed_app_fields.py
index e0b3e340f6..ac280198db 100644
--- a/api/fields/installed_app_fields.py
+++ b/api/fields/installed_app_fields.py
@@ -2,6 +2,8 @@ from flask_restful import fields
 
 from libs.helper import AppIconUrlField, TimestampField
 
+tag_fields = {"id": fields.String, "name": fields.String, "type": fields.String}
+
 app_fields = {
     "id": fields.String,
     "name": fields.String,
@@ -11,6 +13,8 @@ app_fields = {
     "icon_background": fields.String,
     "icon_url": AppIconUrlField,
     "use_icon_as_answer_icon": fields.Boolean,
+    "tags": fields.List(fields.Nested(tag_fields)),
+    "description": fields.String,
 }
 
 installed_app_fields = {
diff --git a/api/fields/workflow_run_fields.py b/api/fields/workflow_run_fields.py
index a106728e9c..b28db9c82c 100644
--- a/api/fields/workflow_run_fields.py
+++ b/api/fields/workflow_run_fields.py
@@ -116,3 +116,10 @@ workflow_run_node_execution_fields = {
 workflow_run_node_execution_list_fields = {
     "data": fields.List(fields.Nested(workflow_run_node_execution_fields)),
 }
+
+workflow_run_statistics_fields = {
+    "total_tokens": fields.Integer,
+    "total_price": fields.Float,
+    "currency": fields.String,
+}
+
diff --git a/api/migrations/versions/2024_11_12_0925-01d6889832f7_add_created_at_index_for_messages.py b/api/migrations/versions/2024_11_12_0925-01d6889832f7_add_created_at_index_for_messages.py
index d94508edcf..59b824abce 100644
--- a/api/migrations/versions/2024_11_12_0925-01d6889832f7_add_created_at_index_for_messages.py
+++ b/api/migrations/versions/2024_11_12_0925-01d6889832f7_add_created_at_index_for_messages.py
@@ -23,9 +23,46 @@ def upgrade():
         batch_op.create_index('message_created_at_idx', ['created_at'], unique=False)
     # ### end Alembic commands ###
 
+    # custom asa commands
+    with op.batch_alter_table('apps', schema=None) as batch_op:
+        batch_op.add_column(sa.Column('asa_company_id', sa.String(length=255), nullable=True))
+
+    with op.batch_alter_table('installed_apps', schema=None) as batch_op:
+        batch_op.add_column(sa.Column('asa_company_id', sa.String(length=255), nullable=True))
+
+    with op.batch_alter_table('workflows', schema=None) as batch_op:
+        batch_op.add_column(sa.Column('asa_company_id', sa.String(length=255), nullable=True))
+
+    with op.batch_alter_table('app_model_configs', schema=None) as batch_op:
+        batch_op.add_column(sa.Column('asa_company_id', sa.String(length=255), nullable=True))
+
+    with op.batch_alter_table('datasets', schema=None) as batch_op:
+        batch_op.add_column(sa.Column('asa_company_id', sa.String(length=255), nullable=True))
+        batch_op.add_column(sa.Column('asa_uid', sa.String(length=255), nullable=True))
+        batch_op.add_column(sa.Column('access_scope', sa.String(length=255), nullable=True))
+    # end of custom asa commands
 
 def downgrade():
     # ### commands auto generated by Alembic - please adjust! ###
     with op.batch_alter_table('messages', schema=None) as batch_op:
         batch_op.drop_index('message_created_at_idx')
     # ### end Alembic commands ###
+
+    # custom asa commands
+    with op.batch_alter_table('apps', schema=None) as batch_op:
+        batch_op.drop_column('asa_company_id')
+
+    with op.batch_alter_table('installed_apps', schema=None) as batch_op:
+        batch_op.drop_column('asa_company_id')
+
+    with op.batch_alter_table('workflows', schema=None) as batch_op:
+        batch_op.drop_column('asa_company_id')
+
+    with op.batch_alter_table('app_model_configs', schema=None) as batch_op:
+        batch_op.drop_column('asa_company_id')
+
+    with op.batch_alter_table('datasets', schema=None) as batch_op:
+        batch_op.drop_column('asa_company_id')
+        batch_op.drop_column('asa_uid')
+        batch_op.drop_column('access_scope')
+    # end of custom asa commands
\ No newline at end of file
diff --git a/api/models/dataset.py b/api/models/dataset.py
index 1ec27203a0..e426ef828a 100644
--- a/api/models/dataset.py
+++ b/api/models/dataset.py
@@ -63,6 +63,9 @@ class Dataset(Base):
     collection_binding_id = db.Column(StringUUID, nullable=True)
     retrieval_model = db.Column(JSONB, nullable=True)
     built_in_field_enabled = db.Column(db.Boolean, nullable=False, server_default=db.text("false"))
+    asa_company_id = db.Column(db.String(255), nullable=True)
+    asa_uid = db.Column(db.String(255), nullable=True)
+    access_scope = db.Column(db.String(255), nullable=True)
 
     @property
     def dataset_keyword_table(self):
diff --git a/api/models/model.py b/api/models/model.py
index b1007c4a79..51336276a2 100644
--- a/api/models/model.py
+++ b/api/models/model.py
@@ -100,7 +100,8 @@ class App(Base):
     updated_by = db.Column(StringUUID, nullable=True)
     updated_at = db.Column(db.DateTime, nullable=False, server_default=func.current_timestamp())
     use_icon_as_answer_icon = db.Column(db.Boolean, nullable=False, server_default=db.text("false"))
-
+    asa_company_id = db.Column(db.String(255), nullable=True)  # New column
+    
     @property
     def desc_or_prompt(self):
         if self.description:
@@ -336,6 +337,7 @@ class AppModelConfig(Base):
     dataset_configs = db.Column(db.Text)
     external_data_tools = db.Column(db.Text)
     file_upload = db.Column(db.Text)
+    asa_company_id = db.Column(db.String(255))
 
     @property
     def app(self):
@@ -478,6 +480,7 @@ class AppModelConfig(Base):
             "completion_prompt_config": self.completion_prompt_config_dict,
             "dataset_configs": self.dataset_configs_dict,
             "file_upload": self.file_upload_dict,
+            "asa_company_id": self.asa_company_id
         }
 
     def from_model_config_dict(self, model_config: Mapping[str, Any]):
@@ -524,6 +527,9 @@ class AppModelConfig(Base):
             json.dumps(model_config.get("dataset_configs")) if model_config.get("dataset_configs") else None
         )
         self.file_upload = json.dumps(model_config.get("file_upload")) if model_config.get("file_upload") else None
+        self.asa_company_id = (
+            json.dumps(model_config.get("asa_company_id")) if model_config.get("asa_company_id") else None
+        ) 
         return self
 
     def copy(self):
@@ -549,6 +555,7 @@ class AppModelConfig(Base):
             completion_prompt_config=self.completion_prompt_config,
             dataset_configs=self.dataset_configs,
             file_upload=self.file_upload,
+            asa_company_id=self.asa_company_id,
         )
 
         return new_app_model_config
@@ -599,6 +606,7 @@ class InstalledApp(Base):
     is_pinned = db.Column(db.Boolean, nullable=False, server_default=db.text("false"))
     last_used_at = db.Column(db.DateTime, nullable=True)
     created_at = db.Column(db.DateTime, nullable=False, server_default=func.current_timestamp())
+    asa_company_id = db.Column(db.String(255), nullable=True)
 
     @property
     def app(self):
diff --git a/api/models/workflow.py b/api/models/workflow.py
index 77d48bec4f..b34a21477e 100644
--- a/api/models/workflow.py
+++ b/api/models/workflow.py
@@ -140,6 +140,8 @@ class Workflow(Base):
         default=datetime.now(UTC).replace(tzinfo=None),
         server_onupdate=func.current_timestamp(),
     )
+    asa_company_id: Mapped[str] = mapped_column(db.String(255), nullable=True)
+
     _environment_variables: Mapped[str] = mapped_column(
         "environment_variables", db.Text, nullable=False, server_default="{}"
     )
@@ -164,6 +166,7 @@ class Workflow(Base):
         conversation_variables: Sequence[Variable],
         marked_name: str = "",
         marked_comment: str = "",
+        asa_company_id: Optional[str] = None,
     ) -> "Workflow":
         workflow = Workflow()
         workflow.id = str(uuid4())
@@ -180,6 +183,7 @@ class Workflow(Base):
         workflow.marked_comment = marked_comment
         workflow.created_at = datetime.now(UTC).replace(tzinfo=None)
         workflow.updated_at = workflow.created_at
+        workflow.asa_company_id = asa_company_id
         return workflow
 
     @property
@@ -189,6 +193,10 @@ class Workflow(Base):
     @property
     def updated_by_account(self):
         return db.session.get(Account, self.updated_by) if self.updated_by else None
+    
+    @property
+    def created_by_company(self):
+        return db.session.get(Account, self.asa_company_id) if self.asa_company_id else None
 
     @property
     def graph_dict(self) -> Mapping[str, Any]:
diff --git a/api/pyproject.toml b/api/pyproject.toml
index 420bc771b6..cc88533c0b 100644
--- a/api/pyproject.toml
+++ b/api/pyproject.toml
@@ -13,6 +13,7 @@ dependencies = [
     "cachetools~=5.3.0",
     "celery~=5.5.2",
     "chardet~=5.1.0",
+    "firebase-admin~=6.5.0",
     "flask~=3.1.0",
     "flask-compress~=1.17",
     "flask-cors~=6.0.0",
diff --git a/api/services/app_dsl_service.py b/api/services/app_dsl_service.py
index 20257fa345..a4fbbecb84 100644
--- a/api/services/app_dsl_service.py
+++ b/api/services/app_dsl_service.py
@@ -127,6 +127,7 @@ class AppDslService:
         icon: Optional[str] = None,
         icon_background: Optional[str] = None,
         app_id: Optional[str] = None,
+        asa_company_id: Optional[str] = None,
     ) -> Import:
         """Import an app from YAML content or URL."""
         import_id = str(uuid.uuid4())
@@ -290,6 +291,7 @@ class AppDslService:
                 icon_type=icon_type,
                 icon=icon,
                 icon_background=icon_background,
+                asa_company_id=asa_company_id,
                 dependencies=check_dependencies_pending_data,
             )
 
@@ -413,6 +415,7 @@ class AppDslService:
         icon_type: Optional[str] = None,
         icon: Optional[str] = None,
         icon_background: Optional[str] = None,
+        asa_company_id: Optional[str] = None,
         dependencies: Optional[list[PluginDependency]] = None,
     ) -> App:
         """Create a new app or update an existing one."""
@@ -438,6 +441,7 @@ class AppDslService:
             app.icon = icon
             app.icon_background = icon_background or app_data.get("icon_background", app.icon_background)
             app.updated_by = account.id
+            app.asa_company_id = asa_company_id
         else:
             if account.current_tenant_id is None:
                 raise ValueError("Current tenant is not set")
@@ -457,6 +461,7 @@ class AppDslService:
             app.use_icon_as_answer_icon = app_data.get("use_icon_as_answer_icon", False)
             app.created_by = account.id
             app.updated_by = account.id
+            app.asa_company_id = asa_company_id
 
             self._session.add(app)
             self._session.commit()
@@ -553,6 +558,10 @@ class AppDslService:
             },
         }
 
+        # Add asa_company_id to the root level if it is not None
+        if app_model.asa_company_id:
+            export_data["asa_company_id"] = app_model.asa_company_id
+
         if app_mode in {AppMode.ADVANCED_CHAT, AppMode.WORKFLOW}:
             cls._append_workflow_export_data(
                 export_data=export_data, app_model=app_model, include_secret=include_secret
diff --git a/api/services/app_service.py b/api/services/app_service.py
index d08462d001..e1a0fd5491 100644
--- a/api/services/app_service.py
+++ b/api/services/app_service.py
@@ -1,10 +1,14 @@
 import json
 import logging
+import os
 from datetime import UTC, datetime
 from typing import Optional, cast
 
+import firebase_admin
+from firebase_admin import credentials
 from flask_login import current_user
 from flask_sqlalchemy.pagination import Pagination
+from google.cloud import firestore
 
 from configs import dify_config
 from constants.model_template import default_app_templates
@@ -383,6 +387,66 @@ class AppService:
                         meta["tool_icons"][tool_name] = {"background": "#252525", "content": "\ud83d\ude01"}
 
         return meta
+    # ASA WIP still need to enable production credentials i think
+    def initialize_firestore_client():
+        """
+        Initialize Firestore client with emulator support or production credentials.
+        """
+        # Check if Firebase has already been initialized
+        try:
+            app = firebase_admin.get_app()
+            print("Firebase already initialized.")
+            return app
+        except ValueError:
+            # No app initialized yet; proceed with initialization.
+            pass
+        use_emulator = True
+        print(f'Are we using emulator? -> {use_emulator}')
+
+        if use_emulator:
+            host = 'localhost'
+            os.environ['FIREBASE_AUTH_EMULATOR_HOST'] = f'{host}:9099'
+            os.environ['FIRESTORE_EMULATOR_HOST'] = f'{host}:8081'
+            os.environ['FIREBASE_DATABASE_EMULATOR_HOST'] = f'{host}:9000'
+            os.environ['STORAGE_EMULATOR_HOST'] = f'http://{host}:9198'
+            os.environ['GOOGLE_CLOUD_PROJECT'] = 'asa-team'
+
+            # Initialize without credentials for emulator
+            firebase_admin.initialize_app(options={"projectId": "asa-team"})
+            print("Firebase initialized successfully for emulator!")
+        else:
+            from firebase_admin import credentials
+            service_account_path = './token-firebase-admin.json'
+            cred = credentials.Certificate(service_account_path)
+            firebase_admin.initialize_app(credential=cred)
+            print("Firebase initialized successfully for production!")
+
+    def export_to_firestore(self, args):
+        """
+        Export app data to Firestore.
+        :param args: Dictionary of app details to store in Firestore.
+        """
+        AppService.initialize_firestore_client()
+
+        app_id = args.get("appID")
+        if not app_id:
+            raise ValueError("appID is required for Firestore export.")
+
+        client = firestore.Client()
+
+        app_data = {
+            "name": args.get("name"),
+            "description": args.get("description"),
+            "icon": args.get("icon"),
+            "icon_background": args.get("icon_background"),
+            "app_id": app_id,
+            "parameter_id": args.get("paramID"),
+            "category": args.get("category"),
+            "has_knowledge": args.get("has_knowledge_base")
+        }
+
+        doc_ref = client.collection("workflows").document(app_id)
+        doc_ref.set(app_data)
 
     @staticmethod
     def get_app_code_by_id(app_id: str) -> str:
diff --git a/api/services/dataset_service.py b/api/services/dataset_service.py
index e42b5ace75..3d3c4c96dd 100644
--- a/api/services/dataset_service.py
+++ b/api/services/dataset_service.py
@@ -174,13 +174,16 @@ class DatasetService:
         provider: str = "vendor",
         external_knowledge_api_id: Optional[str] = None,
         external_knowledge_id: Optional[str] = None,
+        asa_company_id: Optional[str] = None,
+        asa_uid: Optional[str] = None,
+        access_scope: Optional[str] = None,
         embedding_model_provider: Optional[str] = None,
         embedding_model_name: Optional[str] = None,
         retrieval_model: Optional[RetrievalModel] = None,
     ):
         # check if dataset name already exists
-        if db.session.query(Dataset).filter_by(name=name, tenant_id=tenant_id).first():
-            raise DatasetNameDuplicateError(f"Dataset with name {name} already exists.")
+        # if db.session.query(Dataset).filter_by(name=name, tenant_id=tenant_id).first():
+        #     raise DatasetNameDuplicateError(f"Dataset with name {name} already exists.")
         embedding_model = None
         if indexing_technique == "high_quality":
             model_manager = ModelManager()
@@ -219,6 +222,9 @@ class DatasetService:
         dataset.retrieval_model = retrieval_model.model_dump() if retrieval_model else None
         dataset.permission = permission or DatasetPermissionEnum.ONLY_ME
         dataset.provider = provider
+        dataset.asa_company_id = asa_company_id
+        dataset.asa_uid = asa_uid
+        dataset.access_scope = access_scope
         db.session.add(dataset)
         db.session.flush()
 
diff --git a/api/services/workflow_service.py b/api/services/workflow_service.py
index 2be57fd51c..9552a3a488 100644
--- a/api/services/workflow_service.py
+++ b/api/services/workflow_service.py
@@ -212,6 +212,7 @@ class WorkflowService:
                 created_by=account.id,
                 environment_variables=environment_variables,
                 conversation_variables=conversation_variables,
+                asa_company_id=app_model.asa_company_id
             )
             db.session.add(workflow)
         # update draft workflow if found
@@ -222,6 +223,7 @@ class WorkflowService:
             workflow.updated_at = datetime.now(UTC).replace(tzinfo=None)
             workflow.environment_variables = environment_variables
             workflow.conversation_variables = conversation_variables
+            workflow.asa_company_id = app_model.asa_company_id
 
         # commit db session changes
         db.session.commit()
@@ -255,6 +257,7 @@ class WorkflowService:
             tenant_id=app_model.tenant_id,
             app_id=app_model.id,
             type=draft_workflow.type,
+            asa_company_id=app_model.asa_company_id,
             version=Workflow.version_from_datetime(datetime.now(UTC).replace(tzinfo=None)),
             graph=draft_workflow.graph,
             features=draft_workflow.features,
diff --git a/api/uv.lock b/api/uv.lock
index e108e0c445..2e06b29bd3 100644
--- a/api/uv.lock
+++ b/api/uv.lock
@@ -713,6 +713,19 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/84/c2/80633736cd183ee4a62107413def345f7e6e3c01563dbca1417363cf957e/build-1.2.2.post1-py3-none-any.whl", hash = "sha256:1d61c0887fa860c01971625baae8bdd338e517b836a2f70dd1f7aa3a6b2fc5b5", size = 22950, upload-time = "2024-10-06T17:22:23.299Z" },
 ]
 
+[[package]]
+name = "cachecontrol"
+version = "0.14.3"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "msgpack" },
+    { name = "requests" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/58/3a/0cbeb04ea57d2493f3ec5a069a117ab467f85e4a10017c6d854ddcbff104/cachecontrol-0.14.3.tar.gz", hash = "sha256:73e7efec4b06b20d9267b441c1f733664f989fb8688391b670ca812d70795d11", size = 28985, upload-time = "2025-04-30T16:45:06.135Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/81/4c/800b0607b00b3fd20f1087f80ab53d6b4d005515b0f773e4831e37cfa83f/cachecontrol-0.14.3-py3-none-any.whl", hash = "sha256:b35e44a3113f17d2a31c1e6b27b9de6d4405f84ae51baa8c1d3cc5b633010cae", size = 21802, upload-time = "2025-04-30T16:45:03.863Z" },
+]
+
 [[package]]
 name = "cachetools"
 version = "5.3.3"
@@ -1229,6 +1242,7 @@ dependencies = [
     { name = "cachetools" },
     { name = "celery" },
     { name = "chardet" },
+    { name = "firebase-admin" },
     { name = "flask" },
     { name = "flask-compress" },
     { name = "flask-cors" },
@@ -1411,6 +1425,7 @@ requires-dist = [
     { name = "cachetools", specifier = "~=5.3.0" },
     { name = "celery", specifier = "~=5.5.2" },
     { name = "chardet", specifier = "~=5.1.0" },
+    { name = "firebase-admin", specifier = "~=6.5.0" },
     { name = "flask", specifier = "~=3.1.0" },
     { name = "flask-compress", specifier = "~=1.17" },
     { name = "flask-cors", specifier = "~=6.0.0" },
@@ -1743,6 +1758,23 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/18/79/1b8fa1bb3568781e84c9200f951c735f3f157429f44be0495da55894d620/filetype-1.2.0-py2.py3-none-any.whl", hash = "sha256:7ce71b6880181241cf7ac8697a2f1eb6a8bd9b429f7ad6d27b8db9ba5f1c2d25", size = 19970, upload-time = "2022-11-02T17:34:01.425Z" },
 ]
 
+[[package]]
+name = "firebase-admin"
+version = "6.5.0"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "cachecontrol" },
+    { name = "google-api-core", extra = ["grpc"], marker = "platform_python_implementation != 'PyPy'" },
+    { name = "google-api-python-client" },
+    { name = "google-cloud-firestore", marker = "platform_python_implementation != 'PyPy'" },
+    { name = "google-cloud-storage" },
+    { name = "pyjwt", extra = ["crypto"] },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/b5/cf/3460630d2290b0f5982801271404ade7363f5205feb63f781db417a3ebc2/firebase_admin-6.5.0.tar.gz", hash = "sha256:e716dde1447f0a1cd1523be76ff872df33c4e1a3c079564ace033b2ad60bcc4f", size = 99896, upload-time = "2024-03-11T14:53:31.114Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/8a/68/ef35057415342fc14bdc5f7fc999d417de5a4efd25e1352d4df8e40cb628/firebase_admin-6.5.0-py3-none-any.whl", hash = "sha256:fe34ee3ca0e625c5156b3931ca4b4b69b5fc344dbe51bba9706ff674ce277898", size = 126345, upload-time = "2024-03-11T14:53:29.645Z" },
+]
+
 [[package]]
 name = "flask"
 version = "3.1.1"
@@ -2120,6 +2152,22 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/40/86/bda7241a8da2d28a754aad2ba0f6776e35b67e37c36ae0c45d49370f1014/google_cloud_core-2.4.3-py2.py3-none-any.whl", hash = "sha256:5130f9f4c14b4fafdff75c79448f9495cfade0d8775facf1b09c3bf67e027f6e", size = 29348, upload-time = "2025-03-10T21:05:37.785Z" },
 ]
 
+[[package]]
+name = "google-cloud-firestore"
+version = "2.21.0"
+source = { registry = "https://pypi.org/simple" }
+dependencies = [
+    { name = "google-api-core", extra = ["grpc"], marker = "platform_python_implementation != 'PyPy'" },
+    { name = "google-auth", marker = "platform_python_implementation != 'PyPy'" },
+    { name = "google-cloud-core", marker = "platform_python_implementation != 'PyPy'" },
+    { name = "proto-plus", marker = "platform_python_implementation != 'PyPy'" },
+    { name = "protobuf", marker = "platform_python_implementation != 'PyPy'" },
+]
+sdist = { url = "https://files.pythonhosted.org/packages/80/9d/027b9bf61a44422bcdcb00a2acc59152065b1cffa1fc89da62277730973e/google_cloud_firestore-2.21.0.tar.gz", hash = "sha256:0c37faa8506297f827eefc38feb155247a6dcb9a541289631015d125f1b003f8", size = 528159, upload-time = "2025-06-03T19:28:27.195Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/0a/03/94755c64a2fb85cba734ac05a4f80096b8c0acfab0508c9d52c57f571687/google_cloud_firestore-2.21.0-py3-none-any.whl", hash = "sha256:bf33ccc38a27afc60748d1f9bb7c46b078d0d39d288636bdfd967611d7b3f17f", size = 368813, upload-time = "2025-06-03T19:28:25.131Z" },
+]
+
 [[package]]
 name = "google-cloud-resource-manager"
 version = "1.14.2"
@@ -3151,6 +3199,34 @@ wheels = [
     { url = "https://files.pythonhosted.org/packages/5e/75/bd9b7bb966668920f06b200e84454c8f3566b102183bc55c5473d96cb2b9/msal_extensions-1.3.1-py3-none-any.whl", hash = "sha256:96d3de4d034504e969ac5e85bae8106c8373b5c6568e4c8fa7af2eca9dbe6bca", size = 20583, upload-time = "2025-03-14T23:51:03.016Z" },
 ]
 
+[[package]]
+name = "msgpack"
+version = "1.1.1"
+source = { registry = "https://pypi.org/simple" }
+sdist = { url = "https://files.pythonhosted.org/packages/45/b1/ea4f68038a18c77c9467400d166d74c4ffa536f34761f7983a104357e614/msgpack-1.1.1.tar.gz", hash = "sha256:77b79ce34a2bdab2594f490c8e80dd62a02d650b91a75159a63ec413b8d104cd", size = 173555, upload-time = "2025-06-13T06:52:51.324Z" }
+wheels = [
+    { url = "https://files.pythonhosted.org/packages/7f/83/97f24bf9848af23fe2ba04380388216defc49a8af6da0c28cc636d722502/msgpack-1.1.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:71ef05c1726884e44f8b1d1773604ab5d4d17729d8491403a705e649116c9558", size = 82728, upload-time = "2025-06-13T06:51:50.68Z" },
+    { url = "https://files.pythonhosted.org/packages/aa/7f/2eaa388267a78401f6e182662b08a588ef4f3de6f0eab1ec09736a7aaa2b/msgpack-1.1.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:36043272c6aede309d29d56851f8841ba907a1a3d04435e43e8a19928e243c1d", size = 79279, upload-time = "2025-06-13T06:51:51.72Z" },
+    { url = "https://files.pythonhosted.org/packages/f8/46/31eb60f4452c96161e4dfd26dbca562b4ec68c72e4ad07d9566d7ea35e8a/msgpack-1.1.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a32747b1b39c3ac27d0670122b57e6e57f28eefb725e0b625618d1b59bf9d1e0", size = 423859, upload-time = "2025-06-13T06:51:52.749Z" },
+    { url = "https://files.pythonhosted.org/packages/45/16/a20fa8c32825cc7ae8457fab45670c7a8996d7746ce80ce41cc51e3b2bd7/msgpack-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8a8b10fdb84a43e50d38057b06901ec9da52baac6983d3f709d8507f3889d43f", size = 429975, upload-time = "2025-06-13T06:51:53.97Z" },
+    { url = "https://files.pythonhosted.org/packages/86/ea/6c958e07692367feeb1a1594d35e22b62f7f476f3c568b002a5ea09d443d/msgpack-1.1.1-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ba0c325c3f485dc54ec298d8b024e134acf07c10d494ffa24373bea729acf704", size = 413528, upload-time = "2025-06-13T06:51:55.507Z" },
+    { url = "https://files.pythonhosted.org/packages/75/05/ac84063c5dae79722bda9f68b878dc31fc3059adb8633c79f1e82c2cd946/msgpack-1.1.1-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:88daaf7d146e48ec71212ce21109b66e06a98e5e44dca47d853cbfe171d6c8d2", size = 413338, upload-time = "2025-06-13T06:51:57.023Z" },
+    { url = "https://files.pythonhosted.org/packages/69/e8/fe86b082c781d3e1c09ca0f4dacd457ede60a13119b6ce939efe2ea77b76/msgpack-1.1.1-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:d8b55ea20dc59b181d3f47103f113e6f28a5e1c89fd5b67b9140edb442ab67f2", size = 422658, upload-time = "2025-06-13T06:51:58.419Z" },
+    { url = "https://files.pythonhosted.org/packages/3b/2b/bafc9924df52d8f3bb7c00d24e57be477f4d0f967c0a31ef5e2225e035c7/msgpack-1.1.1-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:4a28e8072ae9779f20427af07f53bbb8b4aa81151054e882aee333b158da8752", size = 427124, upload-time = "2025-06-13T06:51:59.969Z" },
+    { url = "https://files.pythonhosted.org/packages/a2/3b/1f717e17e53e0ed0b68fa59e9188f3f610c79d7151f0e52ff3cd8eb6b2dc/msgpack-1.1.1-cp311-cp311-win32.whl", hash = "sha256:7da8831f9a0fdb526621ba09a281fadc58ea12701bc709e7b8cbc362feabc295", size = 65016, upload-time = "2025-06-13T06:52:01.294Z" },
+    { url = "https://files.pythonhosted.org/packages/48/45/9d1780768d3b249accecc5a38c725eb1e203d44a191f7b7ff1941f7df60c/msgpack-1.1.1-cp311-cp311-win_amd64.whl", hash = "sha256:5fd1b58e1431008a57247d6e7cc4faa41c3607e8e7d4aaf81f7c29ea013cb458", size = 72267, upload-time = "2025-06-13T06:52:02.568Z" },
+    { url = "https://files.pythonhosted.org/packages/e3/26/389b9c593eda2b8551b2e7126ad3a06af6f9b44274eb3a4f054d48ff7e47/msgpack-1.1.1-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:ae497b11f4c21558d95de9f64fff7053544f4d1a17731c866143ed6bb4591238", size = 82359, upload-time = "2025-06-13T06:52:03.909Z" },
+    { url = "https://files.pythonhosted.org/packages/ab/65/7d1de38c8a22cf8b1551469159d4b6cf49be2126adc2482de50976084d78/msgpack-1.1.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:33be9ab121df9b6b461ff91baac6f2731f83d9b27ed948c5b9d1978ae28bf157", size = 79172, upload-time = "2025-06-13T06:52:05.246Z" },
+    { url = "https://files.pythonhosted.org/packages/0f/bd/cacf208b64d9577a62c74b677e1ada005caa9b69a05a599889d6fc2ab20a/msgpack-1.1.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:6f64ae8fe7ffba251fecb8408540c34ee9df1c26674c50c4544d72dbf792e5ce", size = 425013, upload-time = "2025-06-13T06:52:06.341Z" },
+    { url = "https://files.pythonhosted.org/packages/4d/ec/fd869e2567cc9c01278a736cfd1697941ba0d4b81a43e0aa2e8d71dab208/msgpack-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:a494554874691720ba5891c9b0b39474ba43ffb1aaf32a5dac874effb1619e1a", size = 426905, upload-time = "2025-06-13T06:52:07.501Z" },
+    { url = "https://files.pythonhosted.org/packages/55/2a/35860f33229075bce803a5593d046d8b489d7ba2fc85701e714fc1aaf898/msgpack-1.1.1-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:cb643284ab0ed26f6957d969fe0dd8bb17beb567beb8998140b5e38a90974f6c", size = 407336, upload-time = "2025-06-13T06:52:09.047Z" },
+    { url = "https://files.pythonhosted.org/packages/8c/16/69ed8f3ada150bf92745fb4921bd621fd2cdf5a42e25eb50bcc57a5328f0/msgpack-1.1.1-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:d275a9e3c81b1093c060c3837e580c37f47c51eca031f7b5fb76f7b8470f5f9b", size = 409485, upload-time = "2025-06-13T06:52:10.382Z" },
+    { url = "https://files.pythonhosted.org/packages/c6/b6/0c398039e4c6d0b2e37c61d7e0e9d13439f91f780686deb8ee64ecf1ae71/msgpack-1.1.1-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:4fd6b577e4541676e0cc9ddc1709d25014d3ad9a66caa19962c4f5de30fc09ef", size = 412182, upload-time = "2025-06-13T06:52:11.644Z" },
+    { url = "https://files.pythonhosted.org/packages/b8/d0/0cf4a6ecb9bc960d624c93effaeaae75cbf00b3bc4a54f35c8507273cda1/msgpack-1.1.1-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:bb29aaa613c0a1c40d1af111abf025f1732cab333f96f285d6a93b934738a68a", size = 419883, upload-time = "2025-06-13T06:52:12.806Z" },
+    { url = "https://files.pythonhosted.org/packages/62/83/9697c211720fa71a2dfb632cad6196a8af3abea56eece220fde4674dc44b/msgpack-1.1.1-cp312-cp312-win32.whl", hash = "sha256:870b9a626280c86cff9c576ec0d9cbcc54a1e5ebda9cd26dab12baf41fee218c", size = 65406, upload-time = "2025-06-13T06:52:14.271Z" },
+    { url = "https://files.pythonhosted.org/packages/c0/23/0abb886e80eab08f5e8c485d6f13924028602829f63b8f5fa25a06636628/msgpack-1.1.1-cp312-cp312-win_amd64.whl", hash = "sha256:5692095123007180dca3e788bb4c399cc26626da51629a31d40207cb262e67f4", size = 72558, upload-time = "2025-06-13T06:52:15.252Z" },
+]
+
 [[package]]
 name = "msrest"
 version = "0.7.1"
diff --git a/docker/docker-compose.yaml b/docker/docker-compose.yaml
index 647af62d96..68b5996520 100644
--- a/docker/docker-compose.yaml
+++ b/docker/docker-compose.yaml
@@ -518,7 +518,11 @@ x-shared-env: &shared-api-worker-env
 services:
   # API service
   api:
-    image: langgenius/dify-api:1.6.0
+    # image: langgenius/dify-api:1.6.0
+    build:
+      context: ../api
+      dockerfile: Dockerfile 
+    image: dify-api:local 
     restart: always
     environment:
       # Use the shared environment variables.
@@ -532,6 +536,13 @@ services:
       PLUGIN_REMOTE_INSTALL_PORT: ${EXPOSE_PLUGIN_DEBUGGING_PORT:-5003}
       PLUGIN_MAX_PACKAGE_SIZE: ${PLUGIN_MAX_PACKAGE_SIZE:-52428800}
       INNER_API_KEY_FOR_PLUGIN: ${PLUGIN_DIFY_INNER_API_KEY:-QaHbTe77CtuXmsfyhR7+vRjI/+XbV1AaFy691iy+kGDv2Jvy0/eAh8Y1}
+      # FIRESTORE_EMULATOR_HOST: host.docker.internal:8081
+      # FIREBASE_AUTH_EMULATOR_HOST: host.docker.internal:9099 # For Firebase Auth
+      # FIREBASE_FUNCTIONS_EMULATOR_HOST: host.docker.internal:5002 # For Firebase Functions
+      # FIREBASE_DATABASE_EMULATOR_HOST: host.docker.internal:9000 # For Firebase Realtime DB
+      # FIREBASE_HOSTING_EMULATOR_HOST: host.docker.internal:5003 # For Firebase Hosting
+      # FIREBASE_PUBSUB_EMULATOR_HOST: host.docker.internal:8085 # For Firebase PubSub
+
     depends_on:
       db:
         condition: service_healthy
@@ -543,6 +554,14 @@ services:
     networks:
       - ssrf_proxy_network
       - default
+    # ports:
+    #   - "5002:5002" # Functions Emulator
+    #   - "8081:8081" # Firestore Emulator
+    #   - "5003:5003" # Hosting Emulator
+    #   - "9099:9099" # Auth Emulator
+    #   - "9000:9000" # Database Emulator
+    #   - "8085:8085" # PubSub Emulator
+
 
   # worker service
   # The Celery worker for processing the queue.
@@ -573,7 +592,11 @@ services:
 
   # Frontend web application.
   web:
-    image: langgenius/dify-web:1.6.0
+    # image: langgenius/dify-web:1.6.0
+    build:
+      context: ../web
+      dockerfile: Dockerfile 
+    image: dify-web:local 
     restart: always
     environment:
       CONSOLE_API_URL: ${CONSOLE_API_URL:-}
@@ -1232,4 +1255,4 @@ networks:
 
 volumes:
   oradata:
-  dify_es01_data:
+  dify_es01_data:
\ No newline at end of file
diff --git a/web/app/(commonLayout)/apps/AppCard.tsx b/web/app/(commonLayout)/apps/AppCard.tsx
index f50cc10520..49a20b0c04 100644
--- a/web/app/(commonLayout)/apps/AppCard.tsx
+++ b/web/app/(commonLayout)/apps/AppCard.tsx
@@ -9,7 +9,7 @@ import cn from '@/utils/classnames'
 import type { App } from '@/types/app'
 import Confirm from '@/app/components/base/confirm'
 import Toast, { ToastContext } from '@/app/components/base/toast'
-import { copyApp, deleteApp, exportAppConfig, updateAppInfo } from '@/service/apps'
+import { copyApp, deleteApp, exportAppConfig, exportToFirestore, updateAppInfo } from '@/service/apps'
 import DuplicateAppModal from '@/app/components/app/duplicate-modal'
 import type { DuplicateAppModalProps } from '@/app/components/app/duplicate-modal'
 import AppIcon from '@/app/components/base/app-icon'
@@ -39,8 +39,8 @@ import { formatTime } from '@/utils/time'
 import { useGetUserCanAccessApp } from '@/service/access-control'
 
 export type AppCardProps = {
-  app: App
-  onRefresh?: () => void
+  app: App;
+  onRefresh?: () => void;
 }
 
 const AppCard = ({ app, onRefresh }: AppCardProps) => {
@@ -50,6 +50,8 @@ const AppCard = ({ app, onRefresh }: AppCardProps) => {
   const { isCurrentWorkspaceEditor } = useAppContext()
   const { onPlanInfoChanged } = useProviderContext()
   const { push } = useRouter()
+  const [showFirestoreExportConfirm, setShowFirestoreExportConfirm] = useState(false)
+  const [hasKnowledgeBase, setHasKnowledgeBase] = useState(false)
 
   const mutateApps = useContextSelector(
     AppsContext,
@@ -67,15 +69,16 @@ const AppCard = ({ app, onRefresh }: AppCardProps) => {
     try {
       await deleteApp(app.id)
       notify({ type: 'success', message: t('app.appDeleted') })
-      if (onRefresh)
-        onRefresh()
+      if (onRefresh) onRefresh()
       mutateApps()
       onPlanInfoChanged()
     }
-    catch (e: any) {
+ catch (e: any) {
       notify({
         type: 'error',
-        message: `${t('app.appDeleteFailed')}${'message' in e ? `: ${e.message}` : ''}`,
+        message: `${t('app.appDeleteFailed')}${
+          'message' in e ? `: ${e.message}` : ''
+        }`,
       })
     }
     setShowConfirmDelete(false)
@@ -129,13 +132,12 @@ const AppCard = ({ app, onRefresh }: AppCardProps) => {
         message: t('app.newApp.appCreated'),
       })
       localStorage.setItem(NEED_REFRESH_APP_LIST_KEY, '1')
-      if (onRefresh)
-        onRefresh()
+      if (onRefresh) onRefresh()
       mutateApps()
       onPlanInfoChanged()
       getRedirection(isCurrentWorkspaceEditor, newApp, push)
     }
-    catch {
+ catch (e) {
       notify({ type: 'error', message: t('app.newApp.appCreateFailed') })
     }
   }
@@ -152,7 +154,7 @@ const AppCard = ({ app, onRefresh }: AppCardProps) => {
       a.download = `${app.name}.yml`
       a.click()
     }
-    catch {
+ catch (e) {
       notify({ type: 'error', message: t('app.exportFailed') })
     }
   }
@@ -163,26 +165,52 @@ const AppCard = ({ app, onRefresh }: AppCardProps) => {
       return
     }
     try {
-      const workflowDraft = await fetchWorkflowDraft(`/apps/${app.id}/workflows/draft`)
-      const list = (workflowDraft.environment_variables || []).filter(env => env.value_type === 'secret')
+      const workflowDraft = await fetchWorkflowDraft(
+        `/apps/${app.id}/workflows/draft`,
+      )
+      const list = (workflowDraft.environment_variables || []).filter(
+        env => env.value_type === 'secret',
+      )
       if (list.length === 0) {
         onExport()
         return
       }
       setSecretEnvList(list)
     }
-    catch {
+ catch (e) {
       notify({ type: 'error', message: t('app.exportFailed') })
     }
   }
 
   const onSwitch = () => {
-    if (onRefresh)
-      onRefresh()
+    if (onRefresh) onRefresh()
     mutateApps()
     setShowSwitchModal(false)
   }
 
+  const handleFirestoreExport = async () => {
+    try {
+      await exportToFirestore({
+        appID: app.id,
+        paramID: app.param_id,
+        name: app.name,
+        icon: app.icon,
+        icon_background: app.icon_background,
+        description: app.description,
+        category: app.mode,
+        has_knowledge_base: hasKnowledgeBase,
+      })
+      setShowFirestoreExportConfirm(false)
+      notify({
+        type: 'success',
+        message: 'Successfully exported to firestore',
+      })
+    }
+ catch (e) {
+      notify({ type: 'error', message: t('app.newApp.appCreateFailed') })
+    }
+  }
+
   const onUpdateAccessControl = useCallback(() => {
     if (onRefresh)
       onRefresh()
@@ -207,6 +235,14 @@ const AppCard = ({ app, onRefresh }: AppCardProps) => {
       e.preventDefault()
       setShowDuplicateModal(true)
     }
+    const onClickFirestoreExport = async (
+      e: React.MouseEvent<HTMLButtonElement>,
+    ) => {
+      e.stopPropagation()
+      props.onClick?.()
+      e.preventDefault()
+      setShowFirestoreExportConfirm(true)
+    }
     const onClickExport = async (e: React.MouseEvent<HTMLButtonElement>) => {
       e.stopPropagation()
       props.onClick?.()
@@ -251,6 +287,9 @@ const AppCard = ({ app, onRefresh }: AppCardProps) => {
         <button className='mx-1 flex h-8 cursor-pointer items-center gap-2 rounded-lg px-3 hover:bg-state-base-hover' onClick={onClickSettings}>
           <span className='system-sm-regular text-text-secondary'>{t('app.editApp')}</span>
         </button>
+        <button className='mx-1 flex h-8 cursor-pointer items-center gap-2 rounded-lg px-3 hover:bg-state-base-hover' onClick={onClickFirestoreExport}>
+          <span className='system-sm-regular text-text-secondary'>Firestore</span>
+        </button>
         <Divider className="my-1" />
         <button className='mx-1 flex h-8 cursor-pointer items-center gap-2 rounded-lg px-3 hover:bg-state-base-hover' onClick={onClickDuplicate}>
           <span className='system-sm-regular text-text-secondary'>{t('app.duplicate')}</span>
@@ -359,7 +398,10 @@ const AppCard = ({ app, onRefresh }: AppCardProps) => {
         </div>
         <div className='title-wrapper h-[90px] px-[14px] text-xs leading-normal text-text-tertiary'>
           <div
-            className={cn(tags.length ? 'line-clamp-2' : 'line-clamp-4', 'group-hover:line-clamp-2')}
+            className={cn(
+              tags.length ? 'line-clamp-2' : 'line-clamp-4',
+              'group-hover:line-clamp-2',
+            )}
             title={app.description}
           >
             {app.description}
@@ -380,8 +422,8 @@ const AppCard = ({ app, onRefresh }: AppCardProps) => {
                   tags.length ? '!block' : '!hidden',
                 )}>
                   <TagSelector
-                    position='bl'
-                    type='app'
+                    position="bl"
+                    type="app"
                     targetID={app.id}
                     value={tags.map(tag => tag.id)}
                     selectedTags={tags}
@@ -466,6 +508,29 @@ const AppCard = ({ app, onRefresh }: AppCardProps) => {
           onCancel={() => setShowConfirmDelete(false)}
         />
       )}
+      {showFirestoreExportConfirm && (
+        <Confirm
+          title="Export to Firestore"
+          content={
+            <>
+              <p>Are you sure you want to export this app to Firestore?</p>
+              <div className="mt-2">
+                <label>
+                  <input
+                    type="checkbox"
+                    checked={hasKnowledgeBase}
+                    onChange={e => setHasKnowledgeBase(e.target.checked)}
+                  />{' '}
+                  Has Knowledge Base
+                </label>
+              </div>
+            </>
+          }
+          isShow={showFirestoreExportConfirm}
+          onConfirm={handleFirestoreExport}
+          onCancel={() => setShowFirestoreExportConfirm(false)}
+        />
+      )}
       {secretEnvList.length > 0 && (
         <DSLExportConfirmModal
           envList={secretEnvList}
diff --git a/web/app/(commonLayout)/apps/Apps.tsx b/web/app/(commonLayout)/apps/Apps.tsx
index 2aa192fb02..cfc5bd9ec4 100644
--- a/web/app/(commonLayout)/apps/Apps.tsx
+++ b/web/app/(commonLayout)/apps/Apps.tsx
@@ -44,13 +44,10 @@ const getKey = (
   if (!pageIndex || previousPageData.has_more) {
     const params: any = { url: 'apps', params: { page: pageIndex + 1, limit: 30, name: keywords, is_created_by_me: isCreatedByMe } }
 
-    if (activeTab !== 'all')
-      params.params.mode = activeTab
-    else
-      delete params.params.mode
+    if (activeTab !== 'all') params.params.mode = activeTab
+    else delete params.params.mode
 
-    if (tags.length)
-      params.params.tag_ids = tags
+    if (tags.length) params.params.tag_ids = tags
 
     return params
   }
@@ -60,7 +57,8 @@ const getKey = (
 const Apps = () => {
   const { t } = useTranslation()
   const router = useRouter()
-  const { isCurrentWorkspaceEditor, isCurrentWorkspaceDatasetOperator } = useAppContext()
+  const { isCurrentWorkspaceEditor, isCurrentWorkspaceDatasetOperator }
+    = useAppContext()
   const showTagManagementModal = useTagStore(s => s.showTagManagementModal)
   const [activeTab, setActiveTab] = useTabSearchParams({
     defaultTab: 'all',
@@ -102,6 +100,22 @@ const Apps = () => {
     },
   )
 
+  // const transformedData = data?.map((page) => ({
+  //   ...page,
+  //   data: page.data.map((app) => {
+  //     const installedApp = installedApps.find(
+  //       (installedApp) => installedApp.app.id === app.id
+  //     );
+
+  //     return installedApp
+  //       ? {
+  //           ...app,
+  //           param_id: installedApp.id,
+  //         }
+  //       : app;
+  //   }),
+  // }));
+
   const anchorRef = useRef<HTMLDivElement>(null)
   const options = [
     { value: 'all', text: t('app.types.all'), icon: <RiApps2Line className='mr-1 h-[14px] w-[14px]' /> },
@@ -120,8 +134,7 @@ const Apps = () => {
   }, [mutate, t])
 
   useEffect(() => {
-    if (isCurrentWorkspaceDatasetOperator)
-      return router.replace('/datasets')
+    if (isCurrentWorkspaceDatasetOperator) return router.replace('/datasets')
   }, [router, isCurrentWorkspaceDatasetOperator])
 
   useEffect(() => {
@@ -144,17 +157,23 @@ const Apps = () => {
     return () => observer?.disconnect()
   }, [isLoading, setSize, anchorRef, mutate, data, error])
 
-  const { run: handleSearch } = useDebounceFn(() => {
-    setSearchKeywords(keywords)
-  }, { wait: 500 })
+  const { run: handleSearch } = useDebounceFn(
+    () => {
+      setSearchKeywords(keywords)
+    },
+    { wait: 500 },
+  )
   const handleKeywordsChange = (value: string) => {
     setKeywords(value)
     handleSearch()
   }
 
-  const { run: handleTagsUpdate } = useDebounceFn(() => {
-    setTagIDs(tagFilterValue)
-  }, { wait: 500 })
+  const { run: handleTagsUpdate } = useDebounceFn(
+    () => {
+      setTagIDs(tagFilterValue)
+    },
+    { wait: 500 },
+  )
   const handleTagsChange = (value: string[]) => {
     setTagFilterValue(value)
     handleTagsUpdate()
diff --git a/web/app/components/base/chat/chat/question.tsx b/web/app/components/base/chat/chat/question.tsx
index d221587940..91d1a21266 100644
--- a/web/app/components/base/chat/chat/question.tsx
+++ b/web/app/components/base/chat/chat/question.tsx
@@ -98,7 +98,7 @@ const Question: FC<QuestionProps> = ({
 
   return (
     <div className='mb-2 flex justify-end last:mb-0'>
-      <div className={cn('group relative mr-4 flex max-w-full items-start pl-14 overflow-x-hidden', isEditing && 'flex-1')}>
+      <div className={cn('group relative mr-4 flex max-w-full items-start overflow-x-hidden pl-14', isEditing && 'flex-1')}>
         <div className={cn('mr-2 gap-1', isEditing ? 'hidden' : 'flex')}>
           <div
             className="absolute hidden gap-0.5 rounded-[10px] border-[0.5px] border-components-actionbar-border bg-components-actionbar-bg p-0.5 shadow-md backdrop-blur-sm group-hover:flex"
diff --git a/web/app/components/base/icons/assets/public/common/lock.svg b/web/app/components/base/icons/assets/public/common/lock.svg
index a6987846f7..5e750ce807 100644
--- a/web/app/components/base/icons/assets/public/common/lock.svg
+++ b/web/app/components/base/icons/assets/public/common/lock.svg
@@ -1,5 +1,5 @@
 <svg width="16" height="16" viewBox="0 0 16 16" fill="none" xmlns="http://www.w3.org/2000/svg">
 <g id="lock">
-<path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M8 1.75C6.27411 1.75 4.875 3.14911 4.875 4.875V6.125C3.83947 6.125 3 6.96444 3 8V12.375C3 13.4106 3.83947 14.25 4.875 14.25H11.125C12.1606 14.25 13 13.4106 13 12.375V8C13 6.96444 12.1606 6.125 11.125 6.125V4.875C11.125 3.14911 9.72587 1.75 8 1.75ZM9.875 6.125V4.875C9.875 3.83947 9.03556 3 8 3C6.96444 3 6.125 3.83947 6.125 4.875V6.125H9.875ZM8 8.625C8.34519 8.625 8.625 8.90481 8.625 9.25V11.125C8.625 11.4702 8.34519 11.75 8 11.75C7.65481 11.75 7.375 11.4702 7.375 11.125V9.25C7.375 8.90481 7.65481 8.625 8 8.625Z" fill="#155AEF"/>
+<path id="Vector" fill-rule="evenodd" clip-rule="evenodd" d="M8 1.75C6.27411 1.75 4.875 3.14911 4.875 4.875V6.125C3.83947 6.125 3 6.96444 3 8V12.375C3 13.4106 3.83947 14.25 4.875 14.25H11.125C12.1606 14.25 13 13.4106 13 12.375V8C13 6.96444 12.1606 6.125 11.125 6.125V4.875C11.125 3.14911 9.72587 1.75 8 1.75ZM9.875 6.125V4.875C9.875 3.83947 9.03556 3 8 3C6.96444 3 6.125 3.83947 6.125 4.875V6.125H9.875ZM8 8.625C8.34519 8.625 8.625 8.90481 8.625 9.25V11.125C8.625 11.4702 8.34519 11.75 8 11.75C7.65481 11.75 7.375 11.4702 7.375 11.125V9.25C7.375 8.90481 7.65481 8.625 8 8.625Z" fill="#785900"/>
 </g>
 </svg>
diff --git a/web/app/components/workflow/nodes/agent/components/tool-icon.tsx b/web/app/components/workflow/nodes/agent/components/tool-icon.tsx
index 8616f34200..4ff0cd780d 100644
--- a/web/app/components/workflow/nodes/agent/components/tool-icon.tsx
+++ b/web/app/components/workflow/nodes/agent/components/tool-icon.tsx
@@ -61,7 +61,7 @@ export const ToolIcon = memo(({ providerName }: ToolIconProps) => {
   >
     <div
       className={classNames(
-        'size-5 border-[0.5px] border-components-panel-border-subtle bg-background-default-dodge relative flex items-center justify-center rounded-[6px]',
+        'relative flex size-5 items-center justify-center rounded-[6px] border-[0.5px] border-components-panel-border-subtle bg-background-default-dodge',
       )}
       ref={containerRef}
     >
@@ -73,7 +73,7 @@ export const ToolIcon = memo(({ providerName }: ToolIconProps) => {
             src={icon}
             alt='tool icon'
             className={classNames(
-              'w-full h-full size-3.5 object-cover',
+              'size-3.5 h-full w-full object-cover',
               notSuccess && 'opacity-50',
             )}
             onError={() => setIconFetchError(true)}
@@ -82,7 +82,7 @@ export const ToolIcon = memo(({ providerName }: ToolIconProps) => {
         if (typeof icon === 'object') {
           return <AppIcon
             className={classNames(
-              'w-full h-full size-3.5 object-cover',
+              'size-3.5 h-full w-full object-cover',
               notSuccess && 'opacity-50',
             )}
             icon={icon?.content}
diff --git a/web/service/apps.ts b/web/service/apps.ts
index d87a98412e..d54ba93750 100644
--- a/web/service/apps.ts
+++ b/web/service/apps.ts
@@ -5,6 +5,10 @@ import type { CommonResponse } from '@/models/common'
 import type { AppIconType, AppMode, ModelConfig } from '@/types/app'
 import type { TracingProvider } from '@/app/(commonLayout)/app/(appDetailLayout)/[appId]/overview/tracing/type'
 
+export const exportToFirestore: Fetcher<AppDetailResponse, { appID: string; paramID?: string | null; name: string; icon: string; icon_background?: string | null; description?: string; category: string; has_knowledge_base: boolean }> = ({ appID, paramID, name, icon, icon_background, description, category, has_knowledge_base }) => {
+  return post<AppDetailResponse>(`apps/${appID}/exportFirestore`, { body: { appID, paramID, name, icon, icon_background, description, category, has_knowledge_base } })
+}
+
 export const fetchAppList: Fetcher<AppListResponse, { url: string; params?: Record<string, any> }> = ({ url, params }) => {
   return get<AppListResponse>(url, { params })
 }
diff --git a/web/themes/tailwind-theme-var-define.ts b/web/themes/tailwind-theme-var-define.ts
index 66a34b06ca..2010d53aab 100644
--- a/web/themes/tailwind-theme-var-define.ts
+++ b/web/themes/tailwind-theme-var-define.ts
@@ -390,6 +390,7 @@ const vars = {
   'background-gradient-bg-fill-chat-bg-2': 'var(--color-background-gradient-bg-fill-chat-bg-2)',
   'background-gradient-bg-fill-chat-bubble-bg-1': 'var(--color-background-gradient-bg-fill-chat-bubble-bg-1)',
   'background-gradient-bg-fill-chat-bubble-bg-2': 'var(--color-background-gradient-bg-fill-chat-bubble-bg-2)',
+  'background-gradient-bg-fill-chat-bubble-bg-3': 'var(--color-background-gradient-bg-fill-chat-bubble-bg-3)',
   'background-gradient-bg-fill-debug-bg-1': 'var(--color-background-gradient-bg-fill-debug-bg-1)',
   'background-gradient-bg-fill-debug-bg-2': 'var(--color-background-gradient-bg-fill-debug-bg-2)',
 
diff --git a/web/types/app.ts b/web/types/app.ts
index 3de5c446ec..0a75603a18 100644
--- a/web/types/app.ts
+++ b/web/types/app.ts
@@ -315,6 +315,8 @@ export type AppIconType = 'image' | 'emoji'
 export type App = {
   /** App ID */
   id: string
+  /** App ID */
+  param_id: string | null
   /** Name */
   name: string
   /** Description */
